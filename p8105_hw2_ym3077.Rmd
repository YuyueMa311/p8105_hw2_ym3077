---
title: "p8105_hw2_ym3077"
output: github_document
---

## Problem 1

Load library
```{r}
library(tidyverse)
library(lubridate)
library(readxl)
```

Load datasets
```{r}
pols_df = read_csv("./data/pols-month.csv")
snp_df = read_csv("./data/snp.csv")
unemp_df = read_csv("./data/unemployment.csv")
```

Clean pols_df
```{r}
pols_df_clean = pols_df |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) |>
  mutate(
    month = month.name[month],
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |>
  select(-day, -prez_gop, -prez_dem)
```

Clean snp_df
```{r}
snp_df_clean = snp_df |>
  mutate(date = mdy(date)) |>                        
  mutate(
    year = year(date),                               
    month = month(date, label = TRUE, abbr = FALSE), 
    day = day(date)                                   
  ) |>
  select(year, month, day, close) |>
  arrange(year, month)

```

Clean unemp_df
```{r}
unemp_df_clean = unemp_df |>
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,                
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(
    month = month.name[match(month, tolower(month.abb))],
    year = year
  ) |>
  select(year, month, unemployment) |>
  arrange(year, match(month, month.name))
```

Merge 3 datasets
```{r}
merged_df = pols_df_clean |>
  left_join(snp_df_clean, by = c("year", "month")) |>
  left_join(unemp_df_clean, by = c("year", "month"))

merged_df
```

Summary:

Three datasets: `pols_df`, `snp_df`, and `unemp_df`, each containing monthly-level U.S. data.   
- The `pols_df` dataset provides information on political composition, including 9 variables such as `year`, `month`, `gov_gop`, `gov_dem`, `sen_gop`, `sen_dem`, `rep_gop`, and `president` indicating the number of officeholders from each party.   
- The `snp_df` dataset includes stock market data with 2 variables： `date` and `close`, where close records the closing values of the S&P stock index on the associated date.   
- The `unemp_df` dataset reports national unemployment rates, originally with columns for each month (Jan to Dec) and a Year column, 68 observations of 13 variables in total:, later pivoted into long format with variables `year`,` month`, and `unemployment`.  

After cleaning and transforming the individual datasets, they were merged using common keys year and month, resulting in a single dataset `merged_df` with 822 rows and 12 columns, spanning the years 1947 to 2015. The merged dataset includes key variables such as `year`, `month`, `president`, `close` (S&P index), and `unemployment`, allowing for integrated analysis of political control, economic conditions, and market trends across nearly seven decades.


## Problem 2


Read and clean Mr. Trash Wheel data
```{r}
mr_trash <- read_excel("data/202409 Trash Wheel Collection Data.xlsx",
                       sheet = "Mr. Trash Wheel", skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls, 0)),
    year = as.integer(year),
    trash_wheel = "Mr. Trash Wheel" 
  ) |>
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards,
         plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags,
         wrappers, sports_balls, homes_powered, trash_wheel)
```

Read and clean Professor Trash Wheel data
```{r}
prof_trash <- read_excel("data/202409 Trash Wheel Collection Data.xlsx",
                         sheet = "Professor Trash Wheel", skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    year = as.integer(year),
    trash_wheel = "Professor Trash Wheel")
```

Read and clean Gwynnda data
```{r}
gwynnda_trash <- read_excel("data/202409 Trash Wheel Collection Data.xlsx",
                            sheet = "Gwynnda Trash Wheel", skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    year = as.integer(year),
    trash_wheel = "Gwynnda Trash Wheel")
```

Combine all Trash Wheel datasets
```{r}
trash_wheel_all <- bind_rows(mr_trash, prof_trash, gwynnda_trash)

trash_wheel_all
```

The combined dataset contains `r nrow(trash_wheel_all)` observations of trash collection records from 3 Trash Wheels in Baltimore: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. Each observation corresponds to a dumpster load of trash, and includes key variables such as the date of collection, weight in tons of trash collected (`weight_tons`), volume in cubic yards (`volume_cubic_yards`), and itemized counts of different trash types like plastic bottles, polystyrene, cigarette butts, glass bottles, plastic bags, etc. A notable variable is `homes_powered`, estimating the number of homes that could be powered using the energy from incinerated trash.  

For the available data, Professor Trash Wheel collected a total of `r sum(trash_wheel_all$weight_tons[trash_wheel_all$trash_wheel == "Professor Trash Wheel"], na.rm = TRUE)` tons of trash. 
In June 2022, Gwynnda collected a total of `r sum(trash_wheel_all$cigarette_butts[trash_wheel_all$trash_wheel == "Gwynnda Trash Wheel" & trash_wheel_all$year == 2022 & trash_wheel_all$month == "June"], na.rm = TRUE)` cigarette butts.


## Problem 3

Load datasets
```{r}
zillow <- read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
 janitor::clean_names()

zipcode <- read_csv("data/Zip Codes.csv") |> 
 janitor::clean_names()
```

Clean datasets
```{r}
names(zillow)

zillow_long <- zillow |> 
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date",
    values_to = "zori"
  ) |>
  mutate(
    date = str_remove(date, "^x"),    
    date = ymd(date),               
    year = year(date),
    month = month(date, label = TRUE, abbr = FALSE),
    zip = as.character(region_name)
  )

zipcode_clean <- zipcode |> 
  select(zip_code, borough = county, neighborhood) |> 
  rename(zip = zip_code) |> 
  mutate(zip = as.character(zip))
```

Merge datasets
```{r}
zillow_merged <- left_join(zillow_long, zipcode_clean, by = "zip", relationship = "many-to-many")
```

Organize merged dataset
```{r}
zillow_merged <- zillow_merged |>
  select(zip, region_id, region_name, region_type, state, city, county_name, borough, 
         neighborhood, year, month, date, zori, everything(), -state_name) |>
  arrange(zip, year, match(month, month.name))
zillow_merged

n_distinct(zillow_merged$zip)
n_distinct(zillow_merged$neighborhood)
```

The resulting tidy dataset `zillow_merged` contains 17,516 observations and 15 variables, where each row represents the rental price index (`zori`) for a specific ZIP code and month. After merging Zillow’s housing data with zipcode geographic information, the tidy dataset includes identifiers for region, state, city, county (`county_name`), borough, and neighborhood. There are 149 unique ZIP codes and 43 unique neighborhoods represented in the data. The `zillow_merged` preserved distinct classification schemes: `county_name` from the original Zillow data and `borough`/`neighborhood` from the ZIP code dataset; allowing for future flexible geographic analysis across multiple administrative levels.





